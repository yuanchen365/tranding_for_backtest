from __future__ import annotations

import io
import sys
import tempfile
from dataclasses import asdict
from datetime import date, datetime
from pathlib import Path
from typing import List

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

PROJECT_ROOT = Path(__file__).resolve().parents[1]
SRC_DIR = PROJECT_ROOT / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))
FUTURES_DATA_DIR = PROJECT_ROOT / "data" / "futures"

from backtester.config import CostConfig, DataConfig, ParamGridEntry, RiskConfig
from backtester.data.loader import DataLoader, DataLoaderError
from backtester.engine.backtester import BacktestEngine
from backtester.engine.costs import CostModel
from backtester.metrics.summary import StrategyPerformance, compute_strategy_performance
from backtester.report.exports import export_csvs
from backtester.report.excel import export_excel
from backtester.report.plots import plot_equity_all_strategies, plot_strategy_charts
from backtester.strategies.base import STRATEGY_REGISTRY, get_strategy
from backtester.utils import load_env_file


st.set_page_config(page_title="Channel Backtest Dashboard", layout="wide")

# Load environment (such as SHIOAJI credentials) on app startup.
load_env_file(".env")
st.title("ğŸ“ˆ å››ç­–ç•¥é€šé“å›æ¸¬å„€è¡¨æ¿")
st.markdown(
    """
    ä¸Šå‚³æˆ–ä¸²æ¥è³‡æ–™ï¼Œè¨­å®š N/L åƒæ•¸ç¶²æ ¼èˆ‡æˆæœ¬æ¨¡å‹ï¼Œä¸¦ç«‹å³å–å¾—ç­–ç•¥ç¸¾æ•ˆèˆ‡äº’å‹•åœ–è¡¨ã€‚<br/>
    æœ¬å·¥å…·éµå¾ªå°ˆæ¡ˆ SSOT è¦æ ¼ï¼Œå¯åŒ¯å‡º Excelã€CSV èˆ‡åœ–æª”ã€‚
    """,
    unsafe_allow_html=True,
)

# ?ï¿½è¨­?ï¿½æ•¸ç¶²æ ¼ Session State
if "param_grid_df" not in st.session_state:
    st.session_state["param_grid_df"] = pd.DataFrame(
        [
            {"n": 10, "l": 20, "slippage": 0.2},
            {"n": 20, "l": 40, "slippage": 0.2},
        ]
    )

if "futures_downloads" not in st.session_state:
    st.session_state["futures_downloads"] = []


def _render_kline_chart(price_df: pd.DataFrame | None, trade_log: pd.DataFrame) -> None:
    if price_df is None or price_df.empty:
        st.info("K ç·šè³‡æ–™å°šæœªè¼‰å…¥ã€‚")
        return

    price = price_df.copy()
    if not isinstance(price.index, pd.DatetimeIndex):
        price.index = pd.to_datetime(price.index)

    required_cols = {"Open", "High", "Low", "Close"}
    if not required_cols.issubset(price.columns):
        missing = ", ".join(sorted(required_cols - set(price.columns)))
        st.warning(f"åƒ¹æ ¼è³‡æ–™ç¼ºå°‘ K ç·šå¿…è¦æ¬„ä½ï¼š{missing}")
        return

    fig = go.Figure(
        data=[
            go.Scatter(
                x=price.index,
                y=price["Close"],
                mode="lines",
                name="æ”¶ç›¤åƒ¹",
                line=dict(color="#1f77b4", width=2),
            )
        ]
    )

    channel_points = trade_log.dropna(subset=["Signal_Rolling_High", "Signal_Rolling_Low"]).copy()
    if not channel_points.empty:
        channel_points["Signal Date"] = pd.to_datetime(channel_points["Signal Date"])
        palette = px.colors.qualitative.Plotly

        for idx, (strategy, grp) in enumerate(channel_points.groupby("Strategy")):
            color = palette[idx % len(palette)]
            grp = grp.sort_values("Signal Date")
            fig.add_trace(
                go.Scatter(
                    x=grp["Signal Date"],
                    y=grp["Signal_Rolling_High"],
                    mode="lines",
                    line=dict(color=color, dash="dash"),
                    name=f"{strategy} é«˜é»é€šé“",
                    legendgroup=strategy,
                )
            )
            fig.add_trace(
                go.Scatter(
                    x=grp["Signal Date"],
                    y=grp["Signal_Rolling_Low"],
                    mode="lines",
                    line=dict(color=color, dash="dot"),
                    name=f"{strategy} ä½é»é€šé“",
                    legendgroup=strategy,
                )
            )

    fig.update_layout(
        height=520,
        hovermode="x unified",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="åƒ¹æ ¼",
        dragmode="pan",
        xaxis_rangeslider_visible=False,
        xaxis=dict(
            rangeselector=dict(
                buttons=[
                    dict(count=1, label="1M", step="month", stepmode="backward"),
                    dict(count=3, label="3M", step="month", stepmode="backward"),
                    dict(count=6, label="6M", step="month", stepmode="backward"),
                    dict(count=1, label="1Y", step="year", stepmode="backward"),
                    dict(label="All", step="all"),
                ]
            ),
            rangeslider=dict(visible=True),
            type="date",
        ),
        yaxis=dict(fixedrange=False),
)
    st.plotly_chart(fig, use_container_width=True, config={"scrollZoom": True})


def _build_data_config(source_mode: str, symbol: str, uploaded_file: io.BytesIO | None) -> DataConfig:
    temp_dir = Path(tempfile.gettempdir()) / "backtester_ui_uploads"
    temp_dir.mkdir(parents=True, exist_ok=True)

    sources = []
    csv_pattern = None
    if source_mode == "CSV ä¸Šå‚³":
        if uploaded_file is None:
            raise ValueError("è«‹å…ˆä¸Šå‚³ CSV æª”æ¡ˆã€‚")
        target_path = temp_dir / f"{symbol}.csv"
        with target_path.open("wb") as fh:
            fh.write(uploaded_file.getvalue())
        sources.append("csv")
        csv_pattern = str(target_path.parent / "{symbol}.csv")
    elif source_mode == "Shioaji API":
        sources.append("shioaji")
    elif source_mode == "CSV + Shioaji Fallback":
        if uploaded_file is None:
            raise ValueError("è«‹æä¾› CSV æª”æ¡ˆä½œç‚ºç¬¬ä¸€ä¾†æºã€‚")
        target_path = temp_dir / f"{symbol}.csv"
        with target_path.open("wb") as fh:
            fh.write(uploaded_file.getvalue())
        sources.extend(["csv", "shioaji"])
        csv_pattern = str(target_path.parent / "{symbol}.csv")
    else:
        raise ValueError(f"æœªçŸ¥è³‡æ–™ä¾†æºï¼š{source_mode}")

    return DataConfig(sources=sources, csv_pattern=csv_pattern)


def _run_backtest(
    symbol: str,
    price_bundle,
    param_entries: List[ParamGridEntry],
    strategies: List[str],
    base_cost: CostConfig,
    base_slippage: float,
    risk_cfg: RiskConfig,
    output_dir: Path,
):
    results = []
    strategy_labels = [f"{code} {get_strategy(code).name}" for code in strategies]

    for entry in param_entries:
        slippage = entry.slippage if entry.slippage is not None else base_slippage
        cost_model = CostModel(
            multiplier=entry.multiplier if entry.multiplier is not None else base_cost.multiplier,
            fee_fixed_per_side=(
                entry.fee_fixed_per_side
                if entry.fee_fixed_per_side is not None
                else base_cost.fee_fixed_per_side
            ),
            fee_rate_per_side=(
                entry.fee_rate_per_side
                if entry.fee_rate_per_side is not None
                else base_cost.fee_rate_per_side
            ),
        )
        engine = BacktestEngine(
            cost_model=cost_model,
            risk_config=risk_cfg,
            slippage=slippage,
        )
        engine_result = engine.simulate(
            symbol=symbol,
            price=price_bundle.data,
            n=entry.n,
            l=entry.l,
            strategy_codes=strategies,
        )

        perfs, perf_df = compute_strategy_performance(
            trade_log=engine_result.trade_log,
            price=engine_result.price,
            cost_model=cost_model,
            risk_config=risk_cfg,
            strategy_labels=strategy_labels,
        )

        results.append(
            {
                "entry": entry,
                "cost_model": cost_model,
                "slippage": slippage,
                "trade_log": engine_result.trade_log,
                "price": engine_result.price,
                "perfs": perfs,
                "performance_df": perf_df,
                "warnings": engine_result.warnings,
                "img_dir": output_dir / f"{symbol}_imgs_{entry.n}_{entry.l}",
            }
        )
    return results


def _download_futures_data(
    symbol_alias: str,
    contract_key: str,
    start_dt: datetime,
    end_dt: datetime,
):
    data_cfg = DataConfig(sources=["shioaji"], csv_pattern=None, symbol_map={symbol_alias: contract_key})
    loader = DataLoader(data_cfg)
    return loader.load_daily(symbol_alias, start_dt, end_dt)


def _save_futures_csv(symbol: str, price_df: pd.DataFrame, start_date: date, end_date: date) -> Path:
    futures_dir = FUTURES_DATA_DIR / symbol
    futures_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{symbol}_{start_date}_{end_date}_{timestamp}.csv"
    export_df = price_df.copy()
    export_df.index.name = "Date"
    path = futures_dir / filename
    export_df.to_csv(path, encoding="utf-8-sig")
    return path


def _persist_outputs(symbol: str, quality_df: pd.DataFrame, summary_df: pd.DataFrame, results: List[dict]) -> None:
    """Mirror CLI è¼¸å‡ºçš„è³‡æ–™å¤¾çµæ§‹ï¼Œæ–¹ä¾¿ä½¿ç”¨è€…åœ¨ ./outputs ä¸‹æ‰¾åˆ°çµæœã€‚"""
    output_root = PROJECT_ROOT / "outputs"
    symbol_dir = output_root / symbol
    symbol_dir.mkdir(parents=True, exist_ok=True)

    quality_path = symbol_dir / f"{symbol}_data_quality.csv"
    quality_df.to_csv(quality_path, index=False, encoding="utf-8-sig")

    if not summary_df.empty:
        summary_path = symbol_dir / f"{symbol}_param_grid_summary_ui.csv"
        summary_df.to_csv(summary_path, index=False, encoding="utf-8-sig")

    for res in results:
        trade_log = res["trade_log"]
        perf_df = res["performance_df"]
        export_csvs(
            output_dir=symbol_dir,
            symbol=symbol,
            n=res["entry"].n,
            l=res["entry"].l,
            trade_log=trade_log,
            performance_df=perf_df,
        )


with st.sidebar:
    st.header("âš™ï¸ å›æ¸¬è¨­å®š")
    source_option = st.selectbox(
        "è³‡æ–™ä¾†æº",
        ["CSV ä¸Šå‚³", "Shioaji API", "CSV + Shioaji Fallback"],
    )
    uploaded_csv = None
    if source_option != "Shioaji API":
        uploaded_csv = st.file_uploader("ä¸Šå‚³æ—¥ K CSV (å« Date/Open/High/Low/Close)", type="csv")

    symbol = st.text_input("å•†å“ä»£ç¢¼", value="0050")
    col_dates = st.columns(2)
    start_date = col_dates[0].date_input("èµ·å§‹æ—¥", value=date(2018, 1, 1))
    end_date = col_dates[1].date_input("çµæŸæ—¥", value=date(2025, 1, 1))

    strategies_selected = st.multiselect(
        "ç­–ç•¥é¸æ“‡",
        options=list(STRATEGY_REGISTRY.keys()),
        default=["S1", "S2", "S3", "S4"],
        format_func=lambda code: f"{code} {STRATEGY_REGISTRY[code].name}",
    )

    st.markdown("#### é è¨­æˆæœ¬æ¨¡å‹")
    default_slippage = st.number_input("é è¨­æ»‘åƒ¹", value=0.2, step=0.05)
    cost_multiplier = st.number_input("æˆæœ¬ Multiplier", value=1.0, step=0.1, min_value=0.1)
    cost_fixed = st.number_input("å›ºå®šè²»/é‚Š", value=0.0, step=0.1, min_value=0.0)
    cost_rate = st.number_input("æ¯”ä¾‹è²»/é‚Š", value=0.0, step=0.0001, min_value=0.0, format="%.4f")

    st.markdown("#### åƒæ•¸ç¶²æ ¼ (å¯æ–°å¢åˆ—)")
    current_grid = st.session_state["param_grid_df"].copy()
    if "slippage" in current_grid.columns:
        current_grid["slippage"] = current_grid["slippage"].fillna(default_slippage)
    else:
        current_grid["slippage"] = default_slippage
    grid_df = st.data_editor(
        current_grid,
        num_rows="dynamic",
        key="param_grid_editor",
        hide_index=True,
        column_config={
            "n": st.column_config.NumberColumn("N", min_value=1, step=1),
            "l": st.column_config.NumberColumn("L", min_value=1, step=1),
            "slippage": st.column_config.NumberColumn("æ»‘åƒ¹", step=0.05),
        },
    )
    st.session_state["param_grid_df"] = grid_df

    st.markdown("#### é¢¨éšªè¨­å®š")
    trading_days = st.number_input("å¹´åŒ–äº¤æ˜“æ—¥æ•¸", value=252, min_value=1)
    risk_free_rate = st.number_input("å¹´åŒ–ç„¡é¢¨éšªåˆ©ç‡", value=0.0, step=0.01)

    run_button = st.button("ğŸš€ åŸ·è¡Œå›æ¸¬", use_container_width=True)

if run_button:
    try:
        data_config = _build_data_config(source_option, symbol, uploaded_csv)
    except ValueError as exc:
        st.error(str(exc))
        st.stop()

    loader = DataLoader(data_config)
    start_dt = datetime.combine(start_date, datetime.min.time())
    end_dt = datetime.combine(end_date, datetime.min.time())

    try:
        price_bundle = loader.load_daily(symbol, start_dt, end_dt)
    except DataLoaderError as exc:
        st.error(f"è¼‰å…¥è³‡æ–™å¤±æ•—ï¼š{exc}")
        st.stop()

    quality_df = pd.DataFrame([price_bundle.diagnostics])
    st.session_state["backtest_quality"] = quality_df
    st.session_state["backtest_symbol"] = symbol

    base_cost_config = CostConfig(
        multiplier=cost_multiplier,
        fee_fixed_per_side=cost_fixed,
        fee_rate_per_side=cost_rate,
    )
    risk_cfg = RiskConfig(trading_days_per_year=int(trading_days), risk_free_rate=risk_free_rate)

    param_entries: List[ParamGridEntry] = []
    for _, row in grid_df.fillna("").iterrows():
        if not str(row.get("n", "")).strip() or not str(row.get("l", "")).strip():
            continue
        try:
            entry = ParamGridEntry(
                n=int(row["n"]),
                l=int(row["l"]),
                slippage=float(row["slippage"]) if row.get("slippage", "") != "" else None,
                multiplier=float(row["multiplier"]) if row.get("multiplier", "") != "" else None,
                fee_fixed_per_side=float(row["fee_fixed_per_side"])
                if row.get("fee_fixed_per_side", "") != ""
                else None,
                fee_rate_per_side=float(row["fee_rate_per_side"])
                if row.get("fee_rate_per_side", "") != ""
                else None,
            )
            param_entries.append(entry)
        except (ValueError, TypeError):
            st.warning(f"å¿½ç•¥ç„¡æ•ˆåˆ—ï¼š{row.to_dict()}")

    if not param_entries:
        st.error("è«‹è‡³å°‘è¨­å®šä¸€çµ„æœ‰æ•ˆçš„ Nã€L åƒæ•¸ã€‚")
        st.stop()

    output_dir = Path(tempfile.gettempdir()) / "backtester_ui_outputs"
    output_dir.mkdir(parents=True, exist_ok=True)

    results = _run_backtest(
        symbol=symbol,
        price_bundle=price_bundle,
        param_entries=param_entries,
        strategies=strategies_selected,
        base_cost=base_cost_config,
        base_slippage=default_slippage,
        risk_cfg=risk_cfg,
        output_dir=output_dir,
    )

    for res in results:
        perf_df = res["performance_df"].reset_index()
        perf_df["N"] = res["entry"].n
        perf_df["L"] = res["entry"].l
        perf_df["Slippage"] = res["slippage"]
        perf_df["Cost_Multiplier"] = res["cost_model"].multiplier
        perf_df["Cost_Fixed_Per_Side"] = res["cost_model"].fee_fixed_per_side
        perf_df["Cost_Rate_Per_Side"] = res["cost_model"].fee_rate_per_side
        perf_df["Missing_Business_Days"] = price_bundle.diagnostics.get("missing_business_days", 0)
        perf_df["Missing_Price_Rows"] = price_bundle.diagnostics.get("missing_price_rows", 0)
        res["performance_table"] = perf_df

    summary_df = (
        pd.concat([res["performance_table"] for res in results], ignore_index=True)
        if results
        else pd.DataFrame()
    )

    st.session_state["backtest_results"] = {
        "results": results,
        "summary": summary_df,
        "symbol": symbol,
        "quality": quality_df,
    }
    _persist_outputs(symbol=symbol, quality_df=quality_df, summary_df=summary_df, results=results)
    st.success("å›æ¸¬å®Œæˆï¼Œå¯æ–¼ä¸‹æ–¹åˆ‡æ›ä¸åŒåƒæ•¸çµ„åˆæª¢è¦–çµæœã€‚")


dashboard_tab, futures_tab = st.tabs(["ğŸ“ˆ å›æ¸¬å„€è¡¨æ¿", "ğŸ“¥ æœŸè²¨è³‡æ–™ä¸‹è¼‰"])

with dashboard_tab:
    payload = st.session_state.get("backtest_results")
    if payload:
        results = payload["results"]
        summary_df = payload["summary"]
        symbol = payload["symbol"]
        quality_df = payload["quality"]

        st.subheader("ğŸ“Š è³‡æ–™å“è³ªæ‘˜è¦")
        st.dataframe(quality_df.T.rename(columns={0: "å€¼"}))

        st.subheader("ğŸ§® åƒæ•¸ç¶²æ ¼ç¸¾æ•ˆç¸½è¡¨")
        if results:
            tabs = st.tabs([f"N={r['entry'].n}, L={r['entry'].l}" for r in results])

            for tab, res in zip(tabs, results):
                perf_df = res["performance_table"]
                with tab:
                    st.dataframe(perf_df, use_container_width=True)

                    trade_log = res["trade_log"]
                    exit_actions = trade_log[trade_log["Action"].isin(["SELL", "BUYTOCOVER"])].copy()
                    if not exit_actions.empty:
                        exit_actions["Date"] = pd.to_datetime(exit_actions["Date"])
                    price_df = res.get("price")

                    overview_tab, kline_tab = st.tabs(["ç¸¾ï¿½??ï¿½è¡¨", "K ç·šï¿½?"])

                    with overview_tab:
                        equity_series = []
                        if not exit_actions.empty:
                            for strategy, group in exit_actions.groupby("Strategy"):
                                strat_series = (
                                    group.sort_values("Date")
                                    .groupby("Date")["Cumulative Net Profit"]
                                    .last()
                                    .rename(strategy)
                                    .astype(float)
                                )
                                if not strat_series.empty:
                                    equity_series.append((strategy, strat_series))

                        if equity_series:
                            st.markdown("###### å…¨éƒ¨ç­–ç•¥ç´¯ç©æ¬Šç›Šï¼ˆå«åˆè¨ˆï¼‰")
                            chart_df = (
                                pd.concat([series.rename(label) for label, series in equity_series], axis=1)
                                .sort_index()
                                .ffill()
                                .fillna(0.0)
                            )
                            chart_df.index.name = "Date"

                            combined_df = chart_df.assign(**{"å…¨éƒ¨ç­–ç•¥åˆè¨ˆ": chart_df.sum(axis=1, min_count=1)})
                            total_long = (
                                combined_df.reset_index()
                                .melt(id_vars="Date", var_name="ç­–ç•¥", value_name="ç´¯ç©æ¬Šç›Š")
                                .dropna()
                            )
                            if total_long.empty:
                                st.info("å…¨éƒ¨ç­–ç•¥å°šç„¡ç´¯ç©æ›²ç·šè³‡æ–™ã€‚")
                            else:
                                total_fig = px.line(total_long, x="Date", y="ç´¯ç©æ¬Šç›Š", color="ç­–ç•¥")
                                total_fig.update_layout(height=400, legend_title_text="ç­–ç•¥", hovermode="x unified")
                                st.plotly_chart(total_fig, use_container_width=True)

                            available_labels = list(chart_df.columns)
                            selected_labels = st.multiselect(
                                "é¸æ“‡ç­–ç•¥é¡¯ç¤ºï¼ˆå¯å¤šé¸ï¼‰",
                                available_labels,
                                default=available_labels,
                                key=f"equity_select_{res['entry'].n}_{res['entry'].l}",
                            )
                            if selected_labels:
                                selected_exits = exit_actions[exit_actions["Strategy"].isin(selected_labels)].copy()
                                if selected_exits.empty:
                                    st.info("æ‰€é¸ç­–ç•¥å°šç„¡æœˆåº¦æç›Šè³‡æ–™ã€‚")
                                else:
                                    selected_exits["YearMonth"] = (
                                        selected_exits["Date"].dt.to_period("M").dt.to_timestamp()
                                    )
                                    monthly_bars = (
                                        selected_exits.groupby(["YearMonth", "Strategy"])["Net Profit"]
                                        .sum()
                                        .reset_index()
                                    )
                                    if monthly_bars.empty:
                                        st.info("æ‰€é¸ç­–ç•¥å°šç„¡æœˆåº¦æç›Šè³‡æ–™ã€‚")
                                    else:
                                        bar_fig = px.bar(
                                            monthly_bars,
                                            x="YearMonth",
                                            y="Net Profit",
                                            color="Strategy",
                                            barmode="group",
                                            labels={"YearMonth": "æœˆä»½", "Net Profit": "æœˆåº¦æ·¨åˆ©", "Strategy": "ç­–ç•¥"},
                                        )
                                        bar_fig.update_layout(height=320, hovermode="x unified")
                                        st.plotly_chart(bar_fig, use_container_width=True)
                            else:
                                st.info("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹ç­–ç•¥ä»¥é¡¯ç¤ºæœˆåº¦æç›Šã€‚")
                        else:
                            st.info("ç´¯ç©æ›²ç·šå°šæœªè¨ˆç®—ã€‚")

                    with kline_tab:
                        _render_kline_chart(price_df, trade_log)

                st.markdown("###### äº¤æ˜“æª”æ¡ˆä¸‹è¼‰")
                trade_csv = res["trade_log"].to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
                st.download_button(
                    label="ä¸‹è¼‰äº¤æ˜“ç´€éŒ„ CSV",
                    data=trade_csv,
                    file_name=f"{symbol}_trade_log_N{res['entry'].n}_L{res['entry'].l}.csv",
                    mime="text/csv",
                    key=f"download_trades_{res['entry'].n}_{res['entry'].l}",
                )

                if res["warnings"]:
                    st.warning("âš ï¸ " + "ï¼›".join(res["warnings"]))
        else:
            st.info("å°šæœªæœ‰å›æ¸¬çµæœï¼Œè«‹æ–¼å·¦å´è¨­å®šå¾ŒåŸ·è¡Œã€‚")

        if not summary_df.empty:
            st.markdown("###### åƒæ•¸ç¶²æ ¼æ‘˜è¦ (åˆä½µ)")
            st.dataframe(summary_df, use_container_width=True)
            csv_bytes = summary_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
            st.download_button(
                label="ä¸‹è¼‰åƒæ•¸ç¶²æ ¼ CSV",
                data=csv_bytes,
                file_name=f"{symbol}_param_grid_summary_ui.csv",
                mime="text/csv",
                key="download_param_grid_summary",
            )
    else:
        st.info("å°šæœªæœ‰å›æ¸¬çµæœï¼Œè«‹æ–¼å·¦å´è¨­å®šå¾ŒåŸ·è¡Œã€‚")

with futures_tab:
    st.subheader("ğŸ“¥ æœŸè²¨è³‡æ–™ä¸‹è¼‰ï¼ˆShioajiï¼‰")
    with st.expander("æ“ä½œèªªæ˜", expanded=False):
        st.markdown(
            "1. è¼¸å…¥å›æ¸¬ä»£ç¢¼ï¼ˆå¦‚ `TFX`ï¼‰ã€‚\n"
            "2. æŒ‡å®š Shioaji åˆç´„éµï¼ˆå»ºè­°å®Œæ•´è·¯å¾‘ï¼Œä¾‹å¦‚ `Futures/TXF/TXFR1`ï¼‰ã€‚\n"
            "3. é¸æ“‡æ—¥æœŸå€é–“å¾ŒæŒ‰ã€ä¸‹è¼‰æ—¥ Kã€ã€‚\n"
            "4. æª”æ¡ˆå°‡å„²å­˜æ–¼ `data/futures/<ä»£ç¢¼>/`ã€‚"
        )

    default_symbol = st.session_state.get("last_futures_symbol", "TFX")
    default_contract = st.session_state.get("last_futures_contract", "TXFR1")
    col_alias, col_contract = st.columns(2)
    futures_symbol = col_alias.text_input("å›æ¸¬å•†å“ä»£ç¢¼", value=default_symbol).strip().upper()
    futures_contract = col_contract.text_input("Shioaji åˆç´„éµ", value=default_contract).strip()

    col_dates = st.columns(2)
    futures_start = col_dates[0].date_input("é–‹å§‹æ—¥æœŸ", value=st.session_state.get("futures_start", date(2018, 1, 1)))
    futures_end = col_dates[1].date_input("çµæŸæ—¥æœŸ", value=st.session_state.get("futures_end", date.today()))

    download_futures = st.button("ä¸‹è¼‰æ—¥ K", key="download_futures_button", use_container_width=True)

    if download_futures:
        if not futures_symbol:
            st.error("è«‹è¼¸å…¥å›æ¸¬å•†å“ä»£ç¢¼ã€‚")
        elif not futures_contract:
            st.error("è«‹è¼¸å…¥ Shioaji åˆç´„éµã€‚")
        elif futures_end < futures_start:
            st.error("çµæŸæ—¥æœŸä¸å¯æ—©æ–¼é–‹å§‹æ—¥æœŸã€‚")
        else:
            import importlib.util, os
            if importlib.util.find_spec("shioaji") is None:
                st.error("å°šæœªå®‰è£ shioaji å¥—ä»¶ï¼Œè«‹å…ˆå®‰è£ï¼špip install shioaji")
            elif not os.getenv("SHIOAJI_API_KEY") or not os.getenv("SHIOAJI_SECRET_KEY"):
                st.error("æœªåµæ¸¬åˆ° Shioaji æ†‘è­‰ï¼ˆSHIOAJI_API_KEY/SHIOAJI_SECRET_KEYï¼‰ã€‚è«‹ç¢ºèª .env ä¸¦é‡æ–°å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼ã€‚")
            else:
                start_dt = datetime.combine(futures_start, datetime.min.time())
                end_dt = datetime.combine(futures_end, datetime.min.time())
                try:
                    with st.spinner("ä¸‹è¼‰ Shioaji æ—¥ç·šè³‡æ–™ä¸­â€¦"):
                        price_bundle = _download_futures_data(
                            symbol_alias=futures_symbol,
                            contract_key=futures_contract,
                            start_dt=start_dt,
                            end_dt=end_dt,
                        )
                except DataLoaderError as exc:
                    st.error(f"ä¸‹è¼‰å¤±æ•—ï¼š{exc}")
                except Exception as exc:  # pragma: no cover - defensive
                    st.error(f"Shioaji ä¸‹è¼‰æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ï¼š{exc}")
                else:
                    save_path = _save_futures_csv(futures_symbol, price_bundle.data, futures_start, futures_end)
                    st.session_state["last_futures_symbol"] = futures_symbol
                    st.session_state["last_futures_contract"] = futures_contract
                    st.session_state["futures_start"] = futures_start
                    st.session_state["futures_end"] = futures_end

                    download_record = {
                        "å•†å“": futures_symbol,
                        "åˆç´„éµ": futures_contract,
                        "é–‹å§‹": futures_start.isoformat(),
                        "çµæŸ": futures_end.isoformat(),
                        "ç­†æ•¸": int(price_bundle.data.shape[0]),
                        "æª”æ¡ˆ": str((FUTURES_DATA_DIR / futures_symbol / save_path.name).relative_to(PROJECT_ROOT)),
                    }
                    st.session_state["futures_downloads"].insert(0, download_record)
                    st.success(f"ä¸‹è¼‰å®Œæˆï¼Œå·²å„²å­˜è‡³ {save_path}")

                    st.markdown("###### æœ€è¿‘ 50 ç­†è³‡æ–™é è¦½")
                    st.dataframe(price_bundle.data.tail(min(len(price_bundle.data), 50)))

                    csv_bytes = price_bundle.data.to_csv(encoding="utf-8-sig").encode("utf-8-sig")
                    st.download_button(
                        label="ç«‹å³ä¸‹è¼‰ CSV",
                        data=csv_bytes,
                        file_name=save_path.name,
                        mime="text/csv",
                        key=f"download_shioaji_csv_{save_path.name}",
                    )

                    diag_df = pd.DataFrame([price_bundle.diagnostics]).T.rename(columns={0: "å€¼"})
                    st.markdown("###### è³‡æ–™å“è³ª")
                    st.dataframe(diag_df)

    if st.session_state["futures_downloads"]:
        st.markdown("###### æœ€è¿‘ä¸‹è¼‰ç´€éŒ„")
        history_df = pd.DataFrame(st.session_state["futures_downloads"])
        st.dataframe(history_df)
